---
title: "Burnout_Meta_PhysicalSymptoms"
author: "H.L. Glandorf"
date: '2022-07-08'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Burnout Outcomes Meta analysis: Physical Symptoms

```{r, warning=FALSE}
library("robumeta")
library("metafor")
library("dplyr")
library(readxl)
library(metaviz)
library(esc)
library(ggplot2)
metadat <- read_excel("metadat.xlsx", col_types = c("numeric", "text", "numeric", "numeric", "text", "text", "text", "text", "text", "numeric", "numeric", "text"))
```

Load libraries and data

```{r}
dat <- escalc(measure = "ZCOR", ri=corr, ni=sample, data=metadat) # calculate fisher's z score and variance
dat <- dat %>% mutate(ssize_invert = 1/sample) # inverting the sample size for later use in moderation analyses
```

Creating separate frames for different constructs (here: physical symptoms)

```{r}
##physical symptoms
sy_dat <- dat %>% 
  filter(outcome=="symptoms") %>% # filtering the data for physical symptoms as an outcome only
  filter(!is.na(yi)) # filtering out missing values in fisher's z score
```

Three-level meta-analysis model (here: physical symptoms)

Simple model
```{r}
mod_sy <- rma.mv(yi = yi, # specify fisher's z score
                V = vi, # specify variance
                slab = authors, # specify authors
                data = sy_dat, # specify data set
                level = 95, # specify confidence level
                random = list(~ 1 | st_id, # specify random effects (here: study id and effect size id)
                ~ 1 | eff_id), 
                method = "REML", # specify method for determining solution (here: restricted maximum likelihood)
                tdist = TRUE) # specify whether t-distribution should be used or not
summary(mod_sy) # show summary of the multilevel meta model
convert_z2r(mod_sy$b) # convert to correlation r
predict.intervals_mod_sy <- predict(mod_sy, digits = 2, level = .95) # determine  prediction intervals
print(predict.intervals_mod_sy) # show prediction intervals
```

Assessing heterogeneity at each level

```{r}
# to see whether the within-study variance is significantly different from zero, we first create a model where the within-study variance is fixed to zero
mod_sy.within <- rma.mv(yi, vi, 
                         data=sy_dat, 
                         sigma2 = c(NA,0), # specifies the variance component and forces the within-study variance to be zero
                         tdist = TRUE, 
                         random = list(~ 1 | st_id, 
                                       ~ 1 | eff_id))

mod_sy.within.result <- summary(mod_sy.within)

# we then do the same with the between-study variance (trsting whether sig different from zero)
mod_sy.between <- rma.mv(yi, vi, 
                          data=sy_dat, 
                          sigma2 = c(0,NA), # force variance component of level 3 to be zero
                          tdist = TRUE, 
                          random = list(~ 1 | st_id, 
                                        ~ 1 | eff_id))
mod_sy.between.result <- summary(mod_sy.between)

## we can then compare the fit of the full model to the within and the between model
## if this is significant then the within/between study variance is significantly different from 0 as the fit of the full model is significantly better than the fit of the reduced model 
## Note from Gucciardi et al (2020): The asymptotic distribution is no longer 1 degree of freeom, so p-value needs to be divided by 2
mod_sy.within.anova <- anova(mod_sy, mod_sy.within)
mod_sy.within.anova
mod_sy.between.anova <- anova(mod_sy, mod_sy.between)
mod_sy.between.anova 
##the partitioning of variance across two levels in not meaningful, as such a simple meta analysis would be appropriate

## define function to calculate the I2 statistic (% if between-studies variation that is due to true differences/% of total variance that is due to heterogeneity)
calculate_I2 <- function(sy_dat, mod_sy){
  W <- diag(1/sy_dat$vi)
  X <- model.matrix(mod_sy)
  P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W
  I2_statistic <- 100 * sum(mod_sy$sigma2) / (sum(mod_sy$sigma2) + (mod_sy$k-mod_sy$p)/sum(diag(P)))
  return (I2_statistic)
}

I2 <- calculate_I2(sy_dat, mod_sy) 
I2

# now, we need to break down how much of the total variance can be attributed to between-cluster heterogeneity and how much can be attributed to within-cluster heterogeneity
# defining a function to update the I2
calculate_I2update <- function(sy_dat, mod_sy){
  W <- diag(1/sy_dat$vi)
  X <- model.matrix(mod_sy)
  P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W
  I2update_statistic <- 100 * mod_sy$sigma2 / (sum(mod_sy$sigma2) + (mod_sy$k-mod_sy$p)/sum(diag(P))) # I2 update calculation no longer uses sum in the first numerator
  return (I2update_statistic)
}

I2update <- calculate_I2update(sy_dat, mod_sy) 
I2update
# 1st value printed = total variance due to between-cluster heterogeneity
# 2nd value printed = total variance due to within-cluster heterogeneity
```

Assessing outliers and influential cases

```{r, warning=FALSE}
# first, we look at Level 3 (between level) for outliers in terms of the studies included
cooks.distance (mod_sy, cluster=sy_dat$st_id)
plot(cooks.distance(mod_sy, cluster=sy_dat$st_id), type="o", pch=19)
# based on the 4/N rule, there are no outlier studies

# now, looking at the individual effects (level 2)
# calculate residuals
resid_d <- residuals(mod_sy) %>%
  scale(center = F, scale = T) # and convert the residuals to z-scores

# plot residuals
par(mar=c(6,6,4,4))  # change margins to use full space
plot(resid_d, type="p", pch=19)
png(filename = "ResidualsPlotPhysSymptoms.png", 
    width = 800, height = 640, 
    pointsize = 12, res = 120)
plot(resid_d, type="p", pch=19)
dev.off() # this executes the plotting

# view studies with outlier residuals
outliers_resid_d <- resid_d %>%
  cbind(sy_dat$authors) %>%                # bind study names for reference
  subset(resid_d > 3.0 | resid_d < - 3.0)  # subset outliers


# Create new dataframe with residual outliers removed
# remove residual outliers 
sy_datresidualoutliers_dropped <- sy_dat %>%
  subset(subset = -3.0 < resid_d & resid_d < 3.0)
View(sy_datresidualoutliers_dropped)

mod_sy.residual <- rma.mv(yi, vi, 
                           data = sy_datresidualoutliers_dropped, # use new dataframe without outliers
                           level = 95,
                           method = "REML", 
                           slab = authors, 
                           tdist = TRUE, 
                           random = list(~ 1 | st_id, 
                                         ~ 1 | eff_id)) 
summary(mod_sy.residual) # summary of meta without outliers

# calculate cook's distance at individual effects (level 2) rather than studies (level 3)
cooks_d <- cooks.distance(mod_sy) #note: this step can take time to execute
plot(cooks_d, type="p", pch=19)
png(filename = "CooksDistancePlotPhysSymptoms.png", 
    width = 800, height = 640, 
    pointsize = 12, res = 120)
plot(cooks_d, type="p", pch=19)
dev.off()

# View outliers with Cooks > 3 * mean
outliers_cooks_d <- cooks_d %>% 
  cbind(sy_dat$authors) %>%           # bind study names for reference
  subset(cooks_d > 3.0*mean(cooks_d)) %>% # subset outliers
  View()

# like above, we are creating a new dataframe with cooks outliers removed
sy_dat_cooksoutliers_dropped <- sy_dat %>%
  cbind(cooks_d) %>%
  filter(cooks_d < 3.0*mean(cooks_d))

View(sy_dat_cooksoutliers_dropped)

mod_sy.cook <- rma.mv(yi, vi, 
                       data = sy_dat_cooksoutliers_dropped,
                       level = 95,
                       method = "REML", 
                       slab = authors, 
                       tdist = TRUE, 
                       random = list(~ 1 | st_id, 
                                     ~ 1 | eff_id))
summary(mod_sy.cook)
convert_z2r(mod_sy.cook$b)
# cooks removes one outlier (Daumiller et al.)
```

Assessing meta bias

```{r}
# starting off with creating functions to reduce coding
# anova: does the moderator have significantly different effects at each level?
# meta_anova model tells us if the moderator is significant/interesting
# intercept = variable coded as 0/alphabetically first, and slopes = different levels of the moderator
meta_anova <- function(sy_dat, moderator){
  anova_result <- rma.mv(yi, vi,
                         data = sy_dat,
                         level = 95,
                         method = "REML",
                         tdist = TRUE,
                         mods = ~moderator,
                         random = ~ 1 | st_id/eff_id)
  return(anova_result)
}

# mods: is each individual moderator level significantly different from 0?
# meta_mods removes the intercept to tell us if each level of the moderator is significantly different from zero
meta_mods <- function(sy_dat, moderator){
  mods_result <- rma.mv(yi, vi,
                        data = sy_dat,
                        level = 95,
                        method = "REML",
                        tdist = TRUE,
                        mods = ~moderator-1, 
                        random = ~1 | st_id/eff_id)
  return(mods_result)
}

# cont: function for continuous moderators
meta_cont <- function(sy_dat, moderator){
  mods_result <- rma.mv(yi, vi,
                        data = sy_dat,
                        level = 95,
                        method = "REML",
                        tdist = TRUE,
                        mods = moderator, # this specification is the only difference in code compared to categorical moderators
                        random = ~1 | st_id/eff_id)
  return(mods_result)
}

# create a function for centering continuous moderators
center_scale <- function(x) {
  scale(x, scale = FALSE)
}

# now, we examine methodological factors as moderations fo the overall pooled effect
# starting with a multilevel extension of egger test
# convert variance of effects into standard error then run the moderation model
sy_dat$sd <- sqrt(sy_dat$vi)
sy_dat$nsqrt <- sqrt(sy_dat$sample)
sy_dat$sei <- sy_dat$sd/sy_dat$nsqrt

multilevel.egger <- meta_anova(sy_dat, sy_dat$sei) # multilevel Egger test
multilevel.egger
# publication.status <- meta_anova(sy_dat, sy_dat$publication) # publication, can't evaluate bc all are journal articles
 

# continuous moderators below
sy_dat$mod_syample_size<-center_scale(sy_dat$ssize_invert) # mean center prior to analysis
sample.size <- meta_cont(sy_dat, sy_dat$mod_syample_size) # sample size
sample.size
```

Substantive moderators: seeing whether including the moderators improves the model

```{r}
# first execute all of the moderator analyses to see which ones are interesting 

# all anovas for possible moderator categories 
# ABQ dimensions
outcome3_anova <- meta_anova(sy_dat, sy_dat$predictor) 
outcome3_anova

# all individual moderator analyses
# ABQ dimensions
outcome3_mods <- meta_mods(sy_dat, sy_dat$predictor) 
outcome3_mods

# compare the full model with and without interesting moderators
sig_mods_anova <- rma.mv(yi, vi,
                         data = sy_dat,
                         level = 95,
                         method = "REML",
                         tdist = TRUE,
                         mods = ~sy_dat$predictor, #add significant moderators here from meta_anova above (here: ABQ dimensions)
                         random = list(~ 1 | st_id, 
                                       ~ 1 | eff_id))

# model comparisons: maximum-likelihood models (rather than REML) are required
mod_sy_ml <- rma.mv(yi, vi, 
                     data = sy_dat,
                     level = 95,
                     method = "ML", # specify estimator here
                     slab = authors, 
                     tdist = TRUE, 
                     random = list(~ 1 | st_id, 
                                   ~ 1 | eff_id)) 

sigmod_ml <- rma.mv(yi, vi,
                    data = sy_dat,
                    level = 95,
                    method = "ML",
                    tdist = TRUE,
                    mods = ~sy_dat$predictor, # add significant moderators here from meta_anova above
                    random = list(~ 1 | st_id, 
                                  ~ 1 | eff_id))
sigmod_ml

# compare model fit using AICc (akaike information criterion-corrected) and BIC (bayesian information criterion)
nomod_syigmod <- anova.rma(mod_sy_ml, sigmod_ml) # no mods vs significant mod

# check out the comparisons
print(nomod_syigmod)
##no sig difference and the reduced one is better

# calculate pseudo r-squared values
res0 <- mod_sy
res1 <- sig_mods_anova
pseudoRlevel3 <- round(max(0, (res0$sigma2[1] - res1$sigma2[1]) / res0$sigma2[1]), 4) ### level 3
pseudoRlevel2 <- round(max(0, (res0$sigma2[2] - res1$sigma2[2]) / res0$sigma2[2]), 4) ### level 2
```

Visualisation 

```{r}
#============
# Forest plot
#============

ks <- c(7) # number of effect sizes in dataset
for (k in ks) {
  png(paste0("physical symptoms forest_k=",formatC(k, format="f", flag="0", width=3, digits=0), res=1000, ".png", sep=""), 
      height = 200 + 30*k^.90, width = 1500) # width and height in pixels rather than mm/inches
  forest(mod_sy,
         order ="obs", # order by effect size
         level = 95,
         xlab = "Performance",
         digits=c(2,2),
         addcred = TRUE, # bounds of the credibility/prediction interval
         xlim=c(-2.5,5), # horizontal limits of the plot region
         alim=c(-2,4), # actual x-axis limits
         at=(c(-2.00, -1.50, -1.00, -0.50, 0, 0.50, 1, 1.50, 2.00, 2.50, 3.00, 3.50, 4.00)), # position of the x-axis tick marks and corresponding labels
         efac=40/(k+10), # vertical expansion factor for confidence interval limits and arrows
         cex= 1.3, # character and symbol expansion factor
         ylim=c(-1,k+3)) # y limits of the plot
  op <- par(font=4) # bold italic font
  text(-2.5, k+2, "Author(s)", pos=4, cex=1.5) 
  text(5, k+2, "Hedges' g [95% CI]", pos=2, cex=1.5)
  par(op)
  dev.off() # executes plots
}

# save as a PDF file rather than PNG
pdf("physical symptoms forest.pdf", width = 17, height = 15, pointsize = 10)
k <- 7
forest(mod_sy,
       order ="obs", # order by effect size
       level = 95,
       xlab = "Performance",
       digits=c(2,2),
       addcred = TRUE, # bounds of the credibility/prediction interval
       xlim=c(-2.5,5), # horizontal limits of the plot region
       alim=c(-2,4), # actual x-axis limits
       at=(c(-2.00, -1.50, -1.00, -0.50, 0, 0.50, 1, 1.50, 2.00, 2.50, 3.00, 3.50, 4.00)), # position of the x-axis tick marks and corresponding labels
       efac=40/(k+10), # vertical expansion factor for confidence interval limits and arrows
       cex= 1.3, # character and symbol expansion factor
       ylim=c(-1,k+3)) # y limits of the plot
op <- par(font=4) # bold italic font
text(-2.5, k+2, "Author(s)", pos=4, cex=1.5) 
text(5, k+2, "Hedges' g [95% CI]", pos=2, cex=1.5)
par(op)
dev.off() # executes plots

#==============================
# Funnel plot to visualise bias
#==============================

# see this article for guidance on interpretation: https://www.bmj.com/content/343/bmj.d4002

cols <- palette.colors(length(unique(sy_dat$st_id)), palette="Alphabet") # use different colours to visualise effects from same study
cols <- cols[as.numeric(factor(sy_dat$st_id))]
par(cex = 0.3, font = 1) #make small, non-bold characters
par(mar=c(4,4,1,2)) #make margins small
#png(filename = "funnel-overall.png", width = 1400, height = 800) #low quality image
#tiff(filename = "funnel-overall.tiff", width = 5600, height = 3200, res = 700, pointsize = 7) #high quality image
pdf("funnel-physical symptoms.pdf", width = 11.2, height = 6.4, pointsize = 10) #pdf (preferred format)
funnel(mod_sy,
       level=c(90, 95, 99), #plot 90%,95%,99% CI's
       cex = 1,
       shade=c("white", "gray", "darkgray"), #shade of CI
       xlab = "Effect size (Hedge's g)", #x axis label
       steps = 5,
       ylim = c(0,1), #y axis limits
       pch = 18, #changed to diamonds
       cex.axis = 1,
       cex.main = 1,
       cex.lab = 1,
       col = cols)
dev.off() #this executes the plotting step

# create sunset enhanced funnel plot to visualise the power of each effect in a meta-analysis
# see this blog for a user-friendly guide for interpretation: https://www.dsquintana.blog/meta-analysis-power-plot/ 
pdf("sunset funnel-physical symptoms.pdf", width = 11.2, height = 6.4, pointsize = 10) 
viz_sunset(mod_sy, 
           text_size = 5,
           point_size = 3,
           true_effect = .15) # true effect that should be assumed from power calculations
dev.off() # executes plots

# Contour enhanced funnel plot with Eggers regression line and trim and fill method
# noting this visualisation occurs for individual effects (level 2) rather than studies (level 3)
pdf("contour enhanced funnel-physical symptoms.pdf", width = 11.2, height = 6.4, pointsize = 10) 
viz_funnel(mod_sy,
           trim_and_fill = T,
           trim_and_fill_side = "left",
           egger = T,
           point_size = 3,
           xlab="Hedges' g",
           method = "REML")
dev.off() # executes plots
```


